{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIHub_Performance.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPOQiM86M5tahVb/e55iN20"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pR5I5cdfOtDd"},"source":["## Mount Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cL7EYRXhc4Ep","executionInfo":{"status":"ok","timestamp":1622789324534,"user_tz":-540,"elapsed":59659,"user":{"displayName":"스기서브","photoUrl":"","userId":"14835118290804188809"}},"outputId":"a7264b20-5074-49f1-e6dc-2979c838eb02"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5r3Ir4kbPlxF"},"source":["## Import Library"]},{"cell_type":"code","metadata":{"id":"rDvXoKxe7Ice"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import time\n","\n","import random\n","random.seed(777)\n","\n","from PIL import Image\n","from torch.autograd import Variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8tVROWGHPyDo"},"source":["## GPU Setting"]},{"cell_type":"code","metadata":{"id":"UxMjbOTc7V7b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622789328364,"user_tz":-540,"elapsed":7,"user":{"displayName":"스기서브","photoUrl":"","userId":"14835118290804188809"}},"outputId":"76ebd489-726c-429c-c122-b6453deb8b55"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","torch.manual_seed(777)\n","if device == 'cuda':\n","  torch.cuda.manual_seed_all(777)\n","\n","print(f'Using PyTorch version: {torch.__version__} / Device: {device}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using PyTorch version: 1.8.1+cu101 / Device: cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wgsS5Ir3Q0MG"},"source":["## Hyperparameters"]},{"cell_type":"code","metadata":{"id":"2xOY5mKGRRYV"},"source":["TRAINPATH = 'drive/MyDrive/Capstone-Design/dataset/AIHub/train' \n","\n","VGGNETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub/VGGNet/model_epoch_100_acc_89.pth'\n","GOOGLENETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub/GoogLeNet/model_epoch_100_acc_97.pth'\n","RESNETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub/ResNet/model_epoch_100_acc_91.pth'\n","\n","AUGVGGNETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub_Aug/VGGNet/model_epoch_100_acc_94.pth'\n","AUGGOOGLENETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub_Aug/GoogLeNet/model_epoch_100_acc_97.pth'\n","AUGRESNETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub_Aug/ResNet/model_epoch_100_acc_97.pth'\n","\n","AUG2VGGNETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub_Aug2/VGGNet/model_epoch_100_acc_87.pth'\n","AUG2GOOGLENETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub_Aug2/GoogLeNet/model_epoch_100_acc_96.pth'\n","AUG2RESNETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub_Aug2/ResNet/model_epoch_100_acc_95.pth'\n","\n","AUG3VGGNETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub_Aug3/VGGNet/model_epoch_100_acc_94.pth'\n","AUG3GOOGLENETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub_Aug3/GoogLeNet/model_epoch_100_acc_96.pth'\n","AUG3RESNETPATH = 'drive/MyDrive/Capstone-Design/model/AIHub_Aug3/ResNet/model_epoch_100_acc_95.pth'\n","\n","BATCHSIZE = 32"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ydIiRpWPT5d"},"source":["## Data Load"]},{"cell_type":"code","metadata":{"id":"HeB6wo2fcKnr"},"source":["transfrom_train = transforms.Compose([\n","                            transforms.Resize(224),\n","                            transforms.ToTensor(),\n","                            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n","                            ])\n","\n","train_dataset = torchvision.datasets.ImageFolder(root=TRAINPATH, transform=transfrom_train)\n","\n","train_len = int((8/10) * len(train_dataset))\n","valid_len = len(train_dataset) - train_len\n","\n","torch.manual_seed(777)\n","train_data, valid_data = torch.utils.data.dataset.random_split(train_dataset, [train_len, valid_len])\n","\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCHSIZE, shuffle=True, num_workers=2)\n","valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=BATCHSIZE, shuffle=False, num_workers=2)\n","\n","classes = ('궤양병', '잎곰팡이병', '점무늬병', '황화잎말림바이러스', '아메리카잎굴파리', '청벌레', '정상')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n7JwEbAScJft","executionInfo":{"status":"ok","timestamp":1622789460810,"user_tz":-540,"elapsed":24,"user":{"displayName":"스기서브","photoUrl":"","userId":"14835118290804188809"}},"outputId":"e992647a-0748-461a-ce50-9daa0251264b"},"source":["print('train :', len(train_data))\n","print('valid :', len(valid_data))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train : 11964\n","valid : 2991\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lYqggSGuP-nL"},"source":["## Define Model"]},{"cell_type":"code","metadata":{"id":"JpzJrdjyCWGn"},"source":["class VGG(nn.Module):\n","    def __init__(self, features, num_classes=1000, init_weights=True):\n","        super(VGG, self).__init__()\n","        \n","        self.features = features # Convolution layer\n","        \n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n","        \n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 7 * 7, 4096), # 크기 다를시 input 수정\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(4096, num_classes),\n","        ) # FC layer\n","        \n","        if init_weights:\n","            self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.features(x) # Convolution \n","        x = self.avgpool(x) # avgpool\n","        x = x.view(x.size(0), -1) #\n","        x = self.classifier(x) # FC layer\n","        return x\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","def make_layers(cfg, batch_norm=False):\n","    layers = []\n","    in_channels = 3\n","    \n","    for v in cfg:\n","        if v == 'M':\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","        else:\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n","            if batch_norm:\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n","            else:\n","                layers += [conv2d, nn.ReLU(inplace=True)]\n","            in_channels = v\n","                     \n","    return nn.Sequential(*layers)\n","\n","cfg = {\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], #8 + 3 =11 == vgg11\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], # 10 + 3 = vgg 13\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'], #13 + 3 = vgg 16\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'], # 16 +3 =vgg 19\n","    'custom' : [64,64,64,'M',128,128,128,'M',256,256,256,'M']\n","}\n","\n","vggnet = VGG(make_layers(cfg['D']), num_classes=7, init_weights=True).to(device)\n","aug_vggnet = VGG(make_layers(cfg['D']), num_classes=7, init_weights=True).to(device)\n","aug2_vggnet = VGG(make_layers(cfg['D']), num_classes=7, init_weights=True).to(device)\n","aug3_vggnet = VGG(make_layers(cfg['D']), num_classes=7, init_weights=True).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1aaJHKSFjlLA"},"source":["class ConvBlock(nn.Module):\n","    \n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n","        super(ConvBlock, self).__init__()\n","        \n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        self.bn = nn.BatchNorm2d(out_channels)\n","        self.act = nn.ReLU()\n","        \n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        x = self.act(x)\n","        return x\n","\n","class InceptionModule(nn.Module):\n","    \n","    def __init__(self, in_channels, f_1x1, f_3x3_r, f_3x3, f_5x5_r, f_5x5, f_pp):\n","        super(InceptionModule, self).__init__()\n","        \n","        self.branch1 = nn.Sequential(\n","            ConvBlock(in_channels, f_1x1, kernel_size=1, stride=1, padding=0)\n","        )\n","        \n","        self.branch2 = nn.Sequential(\n","            ConvBlock(in_channels, f_3x3_r, kernel_size=1, stride=1, padding=0),\n","            ConvBlock(f_3x3_r, f_3x3, kernel_size=3, stride=1, padding=1)\n","        )\n","        \n","        self.branch3 = nn.Sequential(\n","            ConvBlock(in_channels, f_5x5_r, kernel_size=1, stride=1, padding=0),\n","            ConvBlock(f_5x5_r, f_5x5, kernel_size=5, stride=1, padding=2)\n","        )\n","        \n","        self.branch4 = nn.Sequential(\n","            nn.MaxPool2d(3, stride=1, padding=1, ceil_mode=True),\n","            ConvBlock(in_channels, f_pp, kernel_size=1, stride=1, padding=0)\n","        )\n","        \n","    def forward(self, x):\n","        branch1 = self.branch1(x)\n","        branch2 = self.branch2(x)\n","        branch3 = self.branch3(x)\n","        branch4 = self.branch4(x)\n","        \n","        return torch.cat([branch1, branch2, branch3, branch4], 1)\n","\n","\n","class InceptionAux(nn.Module):\n","    \n","    def __init__(self, in_channels, num_classes):\n","        super(InceptionAux, self).__init__()\n","        \n","        self.pool = nn.AdaptiveAvgPool2d((4,4))\n","        self.conv = nn.Conv2d(in_channels, 128, kernel_size=1, stride=1, padding=0)\n","        self.act = nn.ReLU()\n","        self.fc1 = nn.Linear(2048, 1024)\n","        self.dropout = nn.Dropout(0.7)\n","        self.fc2 = nn.Linear(1024, num_classes)\n","    \n","    def forward(self, x):\n","        x = self.pool(x)\n","        \n","        x = self.conv(x)\n","        x = self.act(x)\n","    \n","        x = torch.flatten(x, 1)\n","        \n","        x = self.fc1(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        \n","        x = self.fc2(x)\n","        \n","        return x\n","\n","\n","class GoogLeNet(nn.Module):\n","    \n","    def __init__(self, num_classes = 10):\n","        super(GoogLeNet, self).__init__()\n","      \n","        self.conv1 = ConvBlock(3, 64, kernel_size=7, stride=2, padding=3)\n","        self.pool1 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n","        self.conv2 = ConvBlock(64, 64, kernel_size=1, stride=1, padding=0)\n","        self.conv3 = ConvBlock(64, 192, kernel_size=3, stride=1, padding=1)\n","        self.pool3 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n","        self.inception3A = InceptionModule(in_channels=192,\n","                                           f_1x1=64,\n","                                           f_3x3_r=96,\n","                                           f_3x3=128,\n","                                           f_5x5_r=16,\n","                                           f_5x5=32,\n","                                           f_pp=32)\n","        self.inception3B = InceptionModule(in_channels=256,\n","                                           f_1x1=128,\n","                                           f_3x3_r=128,\n","                                           f_3x3=192,\n","                                           f_5x5_r=32,\n","                                           f_5x5=96,\n","                                           f_pp=64)\n","        self.pool4 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n","        self.inception4A = InceptionModule(in_channels=480,\n","                                           f_1x1=192,\n","                                           f_3x3_r=96,\n","                                           f_3x3=208,\n","                                           f_5x5_r=16,\n","                                           f_5x5=48,\n","                                           f_pp=64)\n","        self.inception4B = InceptionModule(in_channels=512,\n","                                           f_1x1=160,\n","                                           f_3x3_r=112,\n","                                           f_3x3=224,\n","                                           f_5x5_r=24,\n","                                           f_5x5=64,\n","                                           f_pp=64)\n","        self.inception4C = InceptionModule(in_channels=512,\n","                                           f_1x1=128,\n","                                           f_3x3_r=128,\n","                                           f_3x3=256,\n","                                           f_5x5_r=24,\n","                                           f_5x5=64,\n","                                           f_pp=64)\n","        self.inception4D = InceptionModule(in_channels=512,\n","                                           f_1x1=112,\n","                                           f_3x3_r=144,\n","                                           f_3x3=288,\n","                                           f_5x5_r=32,\n","                                           f_5x5=64,\n","                                           f_pp=64)\n","        self.inception4E = InceptionModule(in_channels=528,\n","                                           f_1x1=256,\n","                                           f_3x3_r=160,\n","                                           f_3x3=320,\n","                                           f_5x5_r=32,\n","                                           f_5x5=128,\n","                                           f_pp=128)\n","        self.pool5 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n","        self.inception5A = InceptionModule(in_channels=832,\n","                                           f_1x1=256,\n","                                           f_3x3_r=160,\n","                                           f_3x3=320,\n","                                           f_5x5_r=32,\n","                                           f_5x5=128,\n","                                           f_pp=128)\n","        self.inception5B = InceptionModule(in_channels=832,\n","                                           f_1x1=384,\n","                                           f_3x3_r=192,\n","                                           f_3x3=384,\n","                                           f_5x5_r=48,\n","                                           f_5x5=128,\n","                                           f_pp=128)\n","        self.pool6 = nn.AdaptiveAvgPool2d((1,1))\n","        self.dropout = nn.Dropout(0.4)\n","        self.fc = nn.Linear(1024, num_classes)\n","        \n","        self.aux4A = InceptionAux(512, num_classes) \n","        self.aux4D = InceptionAux(528, num_classes)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.pool1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.pool3(x)\n","        x = self.inception3A(x)\n","        x = self.inception3B(x)\n","        x = self.pool4(x)\n","        x = self.inception4A(x)\n","  \n","        aux1 = self.aux4A(x)\n","        \n","        x = self.inception4B(x)\n","        x = self.inception4C(x)\n","        x = self.inception4D(x)\n","  \n","        aux2 = self.aux4D(x)\n","        \n","        x = self.inception4E(x)\n","        x = self.pool5(x)\n","        x = self.inception5A(x)\n","        x = self.inception5B(x)\n","        x = self.pool6(x)\n","        x = torch.flatten(x,1)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        \n","        return x, aux1, aux2\n","\n","\n","googlenet = GoogLeNet(num_classes=7).to(device)\n","aug_googlenet = GoogLeNet(num_classes=7).to(device)\n","aug2_googlenet = GoogLeNet(num_classes=7).to(device)\n","aug3_googlenet = GoogLeNet(num_classes=7).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mbISfHi18GQx"},"source":["def conv3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = conv1x1(inplanes, planes) #conv1x1(64,64)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = conv3x3(planes, planes, stride) #conv3x3(64,64)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = conv1x1(planes, planes * self.expansion) #conv1x1(64,256)\n","        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x) # 1x1 stride = 1\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out) # 3x3 stride = stride \n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out) # 1x1 stride = 1\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n","        super(ResNet, self).__init__()\n","\n","        self.inplanes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        \n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        \n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        \n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","resnet = ResNet(Bottleneck, [3, 4, 6, 3], 7, True).to(device)\n","aug_resnet = ResNet(Bottleneck, [3, 4, 6, 3], 7, True).to(device)\n","aug2_resnet = ResNet(Bottleneck, [3, 4, 6, 3], 7, True).to(device)\n","aug3_resnet = ResNet(Bottleneck, [3, 4, 6, 3], 7, True).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WJW93rEVQjKR"},"source":["## Load Model"]},{"cell_type":"code","metadata":{"id":"C4mYDwDsFmhV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622790124365,"user_tz":-540,"elapsed":4468,"user":{"displayName":"스기서브","photoUrl":"","userId":"14835118290804188809"}},"outputId":"4b8cfd1f-68d9-424c-db43-28d56a83ef1a"},"source":["vggnet.load_state_dict(torch.load(VGGNETPATH))\n","googlenet.load_state_dict(torch.load(GOOGLENETPATH))\n","resnet.load_state_dict(torch.load(RESNETPATH))\n","\n","aug_vggnet.load_state_dict(torch.load(AUGVGGNETPATH))\n","aug_googlenet.load_state_dict(torch.load(AUGGOOGLENETPATH))\n","aug_resnet.load_state_dict(torch.load(AUGRESNETPATH))\n","\n","aug2_vggnet.load_state_dict(torch.load(AUG2VGGNETPATH))\n","aug2_googlenet.load_state_dict(torch.load(AUG2GOOGLENETPATH))\n","aug2_resnet.load_state_dict(torch.load(AUG2RESNETPATH))\n","\n","aug3_vggnet.load_state_dict(torch.load(AUG3VGGNETPATH))\n","aug3_googlenet.load_state_dict(torch.load(AUG3GOOGLENETPATH))\n","aug3_resnet.load_state_dict(torch.load(AUG3RESNETPATH))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"mABu444Ji2FY"},"source":["## Performance"]},{"cell_type":"code","metadata":{"id":"rpTGfzrGlu2u"},"source":["IMAGEPATH = 'drive/MyDrive/Capstone-Design/dataset/AIHub/train/4/11_3.jpg'\n","\n","trans = transforms.Compose([\n","                             transforms.Resize(224),\n","                             transforms.ToTensor(),\n","                             transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n","\n","def image_loader(image_name):\n","  image = Image.open(image_name)\n","  image = trans(image).float()\n","  image = Variable(image, requires_grad=True)\n","  image = image.unsqueeze(0)\n","  return image.cuda()\n","\n","image = image_loader(IMAGEPATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XJ0fSSMUjIVm"},"source":["def model_accuracy(model, google=False):\n","  correct = 0\n","  total = 0\n","\n","  class_correct = list(0. for i in range(7))\n","  class_total = list(0. for i in range(7))\n","\n","  with torch.no_grad():\n","      for data in valid_loader:\n","          images, labels = data\n","          images = images.to(device)\n","          labels = labels.to(device)\n","\n","          if google:\n","            outputs, aux1, aux2 = model(images)\n","          else:\n","            outputs = model(images)\n","\n","          _, predicted = torch.max(outputs, 1)\n","\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","          c = (predicted == labels).squeeze()\n","          for i in range(len(labels)):\n","              label = labels[i]\n","              class_correct[label] += c[i].item()\n","              class_total[label] += 1\n","\n","  print(f'Accuracy of the network on the {len(valid_data)} test images: {(100 * correct)/total:.2f} %')\n","\n","  for i in range(7):\n","      print('Accuracy of %s : %.2f %%' % (\n","          classes[i], 100 * class_correct[i] / class_total[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HclQsaaBh-l-"},"source":["from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n","\n","def performance(model, google_net=False):\n","  test = []\n","  pred = []\n","\n","  model.eval()\n","\n","  with torch.no_grad():\n","    for data in valid_loader:\n","      images, labels = data\n","      images = images.to(device)\n","      labels = labels.to(device)\n","      \n","      if google_net:\n","        outputs, aux1, aux2 = model(images)\n","      else:\n","        outputs = model(images)\n","\n","      _, predicted = torch.max(outputs.data, 1)\n","\n","      for i in range(len(labels)):\n","        test.append(int(labels[i]))\n","        pred.append(int(predicted[i]))\n","\n","  confusion = confusion_matrix(test, pred)\n","  accuracy = accuracy_score(test, pred)\n","  precision = precision_score(test, pred, average='macro')\n","  recall = recall_score(test, pred, average='macro')\n","  f1 = f1_score(test, pred, average='macro')\n","\n","  print('Confusion Matrix')\n","  print(confusion)\n","  print()\n","  print(f'accuracy  : {accuracy:.6}')\n","  print(f'precision : {precision:.6}')\n","  print(f'recall    : {recall:.6}')\n","  print(f'f1-score  : {f1:.6}')\n","    \n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bFI8PjtWSjzN"},"source":["def single_predict(image, model, google_net=False):\n","  start = time.time()\n","  if google_net:\n","    outputs, aux1, aux2 = model(image)\n","  else:\n","    outputs = model(image)\n","  _, predicted = torch.max(outputs.data, 1)\n","  end = time.time()\n","  print(f'predicted {predicted}')\n","  print(f'time {end - start}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6IXZCN_CSTIO"},"source":["def performances(image, model, google=False):\n","  performance(model, google)\n","  print()\n","  model_accuracy(model, google)\n","  print()\n","  single_predict(image, model, google)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfY8Q9wsTFDV","executionInfo":{"status":"ok","timestamp":1622783917732,"user_tz":-540,"elapsed":113389,"user":{"displayName":"스기서브","photoUrl":"","userId":"14835118290804188809"}},"outputId":"b2ae8f46-e34c-451f-eda4-9521efe1af21"},"source":["print('--------------VGGNet--------------')\n","performances(image, vggnet, False)\n","print()\n","\n","print('--------------Aug VGGNet--------------')\n","performances(image, aug_vggnet, False)\n","print()\n","\n","print('--------------Aug2 VGGNet--------------')\n","performances(image, aug2_vggnet, False)\n","print()\n","\n","print('--------------Aug3 VGGNet--------------')\n","performances(image, aug3_vggnet, False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--------------VGGNet--------------\n","Confusion Matrix\n","[[  19    0    8    7    4    2    2]\n"," [   0  118    5    0   10    0   13]\n"," [   0    1  336    1   22    0   27]\n"," [   3    0    2   44   15    0   13]\n"," [   0    2   10    5  624    2   84]\n"," [   2    0   11    2    4    5    8]\n"," [   0    1   10    6   37    0 1526]]\n","\n","accuracy  : 0.893347\n","precision : 0.807797\n","recall    : 0.668663\n","f1-score  : 0.713845\n","\n","Accuracy of the network on the 2991 test images: 89.33 %\n","Accuracy of 궤양병 : 45.24 %\n","Accuracy of 잎곰팡이병 : 80.82 %\n","Accuracy of 점무늬병 : 86.82 %\n","Accuracy of 황화잎말림바이러스 : 57.14 %\n","Accuracy of 아메리카잎굴파리 : 85.83 %\n","Accuracy of 청벌레 : 15.62 %\n","Accuracy of 정상 : 96.58 %\n","\n","predicted tensor([4], device='cuda:0')\n","time 0.004988431930541992\n","\n","--------------Aug VGGNet--------------\n","Confusion Matrix\n","[[  30    0    1    4    6    0    1]\n"," [   0  126    1    0    9    1    9]\n"," [   2    2  369    0    7    1    6]\n"," [   2    0    2   58    4    0   11]\n"," [   0    1    9    1  681    1   34]\n"," [   1    0    6    1    6   12    6]\n"," [   0    2    6    2   20    3 1547]]\n","\n","accuracy  : 0.943831\n","precision : 0.884075\n","recall    : 0.796411\n","f1-score  : 0.832381\n","\n","Accuracy of the network on the 2991 test images: 94.38 %\n","Accuracy of 궤양병 : 71.43 %\n","Accuracy of 잎곰팡이병 : 86.30 %\n","Accuracy of 점무늬병 : 95.35 %\n","Accuracy of 황화잎말림바이러스 : 75.32 %\n","Accuracy of 아메리카잎굴파리 : 93.67 %\n","Accuracy of 청벌레 : 37.50 %\n","Accuracy of 정상 : 97.91 %\n","\n","predicted tensor([4], device='cuda:0')\n","time 0.005063056945800781\n","\n","--------------Aug2 VGGNet--------------\n","Confusion Matrix\n","[[  11    1    4   13    5    0    8]\n"," [   1  115    0    0    5    0   25]\n"," [   2    1  329    2   12    0   41]\n"," [   3    0    6   57    3    0    8]\n"," [   3    1   19    0  524    0  180]\n"," [   4    0    1    0   10    0   17]\n"," [   0    1    6    1    5    0 1567]]\n","\n","accuracy  : 0.870277\n","precision : 0.697836\n","recall    : 0.621787\n","f1-score  : 0.651829\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy of the network on the 2991 test images: 87.03 %\n","Accuracy of 궤양병 : 26.19 %\n","Accuracy of 잎곰팡이병 : 78.77 %\n","Accuracy of 점무늬병 : 85.01 %\n","Accuracy of 황화잎말림바이러스 : 74.03 %\n","Accuracy of 아메리카잎굴파리 : 72.08 %\n","Accuracy of 청벌레 : 0.00 %\n","Accuracy of 정상 : 99.18 %\n","\n","predicted tensor([6], device='cuda:0')\n","time 0.005243778228759766\n","\n","--------------Aug3 VGGNet--------------\n","Confusion Matrix\n","[[  27    0    7    4    1    0    3]\n"," [   1  123    7    0    4    0   11]\n"," [   1   10  351    3    4    0   18]\n"," [   1    1    3   59    2    0   11]\n"," [   2    0    7    0  702    4   12]\n"," [   0    0    1    1    3   20    7]\n"," [   1    2   13    9    4    0 1551]]\n","\n","accuracy  : 0.947175\n","precision : 0.881588\n","recall    : 0.818684\n","f1-score  : 0.846327\n","\n","Accuracy of the network on the 2991 test images: 94.72 %\n","Accuracy of 궤양병 : 64.29 %\n","Accuracy of 잎곰팡이병 : 84.25 %\n","Accuracy of 점무늬병 : 90.70 %\n","Accuracy of 황화잎말림바이러스 : 76.62 %\n","Accuracy of 아메리카잎굴파리 : 96.56 %\n","Accuracy of 청벌레 : 62.50 %\n","Accuracy of 정상 : 98.16 %\n","\n","predicted tensor([4], device='cuda:0')\n","time 0.0019061565399169922\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XaWxp4N2c5sW","executionInfo":{"status":"ok","timestamp":1622783995250,"user_tz":-540,"elapsed":76392,"user":{"displayName":"스기서브","photoUrl":"","userId":"14835118290804188809"}},"outputId":"2d178bdb-e8b0-474d-a98a-e4fbbe6e16f3"},"source":["print('--------------GoogLeNet--------------')\n","performances(image, googlenet, True)\n","print()\n","\n","print('--------------Aug GoogLeNet--------------')\n","performances(image, aug_googlenet, True)\n","print()\n","\n","print('--------------Aug2 GoogLeNet--------------')\n","performances(image, aug2_googlenet, True)\n","print()\n","\n","print('--------------Aug3 GoogLeNet--------------')\n","performances(image, aug3_googlenet, True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--------------GoogLeNet--------------\n","Confusion Matrix\n","[[  40    1    0    1    0    0    0]\n"," [   0  137    1    0    3    2    3]\n"," [   1    0  384    0    2    0    0]\n"," [   0    0    1   72    0    1    3]\n"," [   0    3    2    0  709    4    9]\n"," [   1    1    1    0    1   21    7]\n"," [   0    0    3    3    8    0 1566]]\n","\n","accuracy  : 0.979271\n","precision : 0.937273\n","recall    : 0.920097\n","f1-score  : 0.928199\n","\n","Accuracy of the network on the 2991 test images: 97.93 %\n","Accuracy of 궤양병 : 95.24 %\n","Accuracy of 잎곰팡이병 : 93.84 %\n","Accuracy of 점무늬병 : 99.22 %\n","Accuracy of 황화잎말림바이러스 : 93.51 %\n","Accuracy of 아메리카잎굴파리 : 97.52 %\n","Accuracy of 청벌레 : 65.62 %\n","Accuracy of 정상 : 99.11 %\n","\n","predicted tensor([4], device='cuda:0')\n","time 0.015490055084228516\n","\n","--------------Aug GoogLeNet--------------\n","Confusion Matrix\n","[[  40    0    1    0    0    0    1]\n"," [   0  138    2    0    1    1    4]\n"," [   0    0  386    0    0    0    1]\n"," [   0    0    1   73    0    1    2]\n"," [   0    2    4    0  716    0    5]\n"," [   1    1    0    1    0   26    3]\n"," [   0    0    0    5    4    0 1571]]\n","\n","accuracy  : 0.986292\n","precision : 0.967091\n","recall    : 0.947818\n","f1-score  : 0.956804\n","\n","Accuracy of the network on the 2991 test images: 98.63 %\n","Accuracy of 궤양병 : 95.24 %\n","Accuracy of 잎곰팡이병 : 94.52 %\n","Accuracy of 점무늬병 : 99.74 %\n","Accuracy of 황화잎말림바이러스 : 94.81 %\n","Accuracy of 아메리카잎굴파리 : 98.49 %\n","Accuracy of 청벌레 : 81.25 %\n","Accuracy of 정상 : 99.43 %\n","\n","predicted tensor([4], device='cuda:0')\n","time 0.014220714569091797\n","\n","--------------Aug2 GoogLeNet--------------\n","Confusion Matrix\n","[[  37    0    0    2    0    2    1]\n"," [   0  135    0    0    6    0    5]\n"," [   0    1  381    0    1    0    4]\n"," [   0    0    0   71    0    1    5]\n"," [   1    1    1    0  713    6    5]\n"," [   0    0    0    0    4   26    2]\n"," [   0    0    0    1    5  153 1421]]\n","\n","accuracy  : 0.930792\n","precision : 0.859576\n","recall    : 0.914971\n","f1-score  : 0.85232\n","\n","Accuracy of the network on the 2991 test images: 93.08 %\n","Accuracy of 궤양병 : 88.10 %\n","Accuracy of 잎곰팡이병 : 92.47 %\n","Accuracy of 점무늬병 : 98.45 %\n","Accuracy of 황화잎말림바이러스 : 92.21 %\n","Accuracy of 아메리카잎굴파리 : 98.07 %\n","Accuracy of 청벌레 : 81.25 %\n","Accuracy of 정상 : 89.94 %\n","\n","predicted tensor([4], device='cuda:0')\n","time 0.015576362609863281\n","\n","--------------Aug3 GoogLeNet--------------\n","Confusion Matrix\n","[[  33    1    6    2    0    0    0]\n"," [   0  133    2    0    4    0    7]\n"," [   2    1  371    0    3    0   10]\n"," [   1    0    8   57    0    2    9]\n"," [   0    0    2    0  720    2    3]\n"," [   0    0    1    1    2   22    6]\n"," [   0    4   12    3    0    1 1560]]\n","\n","accuracy  : 0.968238\n","precision : 0.925953\n","recall    : 0.865829\n","f1-score  : 0.893094\n","\n","Accuracy of the network on the 2991 test images: 96.82 %\n","Accuracy of 궤양병 : 78.57 %\n","Accuracy of 잎곰팡이병 : 91.10 %\n","Accuracy of 점무늬병 : 95.87 %\n","Accuracy of 황화잎말림바이러스 : 74.03 %\n","Accuracy of 아메리카잎굴파리 : 99.04 %\n","Accuracy of 청벌레 : 68.75 %\n","Accuracy of 정상 : 98.73 %\n","\n","predicted tensor([4], device='cuda:0')\n","time 0.014600753784179688\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fx2ydnV7c55G","executionInfo":{"status":"ok","timestamp":1622784085189,"user_tz":-540,"elapsed":88679,"user":{"displayName":"스기서브","photoUrl":"","userId":"14835118290804188809"}},"outputId":"2a365e7d-416d-4755-8c13-b961e56b4e8f"},"source":["print('--------------ResNet--------------')\n","performances(image, resnet, False)\n","print()\n","\n","print('--------------Aug ResNet--------------')\n","performances(image, aug_resnet, False)\n","print()\n","\n","print('--------------Aug2 ResNet--------------')\n","performances(image, aug2_resnet, False)\n","print()\n","\n","print('--------------Aug3 ResNet--------------')\n","performances(image, aug3_resnet, False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--------------ResNet--------------\n","Confusion Matrix\n","[[  32    1    0    3    2    0    4]\n"," [   1  117    0    0    7    1   20]\n"," [   0    0  337    4   22    0   24]\n"," [   0    0    2   64    0    1   10]\n"," [   1    0    7    1  655    2   61]\n"," [   0    0    3    1    9    9   10]\n"," [   5    2   11    6   21    1 1534]]\n","\n","accuracy  : 0.918756\n","precision : 0.860263\n","recall    : 0.774049\n","f1-score  : 0.805398\n","\n","Accuracy of the network on the 2991 test images: 91.88 %\n","Accuracy of 궤양병 : 76.19 %\n","Accuracy of 잎곰팡이병 : 80.14 %\n","Accuracy of 점무늬병 : 87.08 %\n","Accuracy of 황화잎말림바이러스 : 83.12 %\n","Accuracy of 아메리카잎굴파리 : 90.10 %\n","Accuracy of 청벌레 : 28.12 %\n","Accuracy of 정상 : 97.09 %\n","\n","predicted tensor([4], device='cuda:0')\n","time 0.016103029251098633\n","\n","--------------Aug ResNet--------------\n","Confusion Matrix\n","[[  37    1    0    2    1    0    1]\n"," [   2  135    4    0    2    0    3]\n"," [   0    3  377    0    3    1    3]\n"," [   1    0    0   70    0    1    5]\n"," [   0    2    3    0  714    2    6]\n"," [   0    1    2    1    4   20    4]\n"," [   0    0    5    0    1    0 1574]]\n","\n","accuracy  : 0.978602\n","precision : 0.943311\n","recall    : 0.898883\n","f1-score  : 0.918766\n","\n","Accuracy of the network on the 2991 test images: 97.86 %\n","Accuracy of 궤양병 : 88.10 %\n","Accuracy of 잎곰팡이병 : 92.47 %\n","Accuracy of 점무늬병 : 97.42 %\n","Accuracy of 황화잎말림바이러스 : 90.91 %\n","Accuracy of 아메리카잎굴파리 : 98.21 %\n","Accuracy of 청벌레 : 62.50 %\n","Accuracy of 정상 : 99.62 %\n","\n","predicted tensor([4], device='cuda:0')\n","time 0.009586095809936523\n","\n","--------------Aug2 ResNet--------------\n","Confusion Matrix\n","[[  35    1    0    1    0    0    5]\n"," [   2  122    1    0    5    0   16]\n"," [   0    0  371    1    4    0   11]\n"," [   0    0    1   63    0    0   13]\n"," [   1    1    3    0  687    2   33]\n"," [   1    0    2    0    6   14    9]\n"," [   0    0    0    0    2    0 1578]]\n","\n","accuracy  : 0.959545\n","precision : 0.947231\n","recall    : 0.832429\n","f1-score  : 0.877319\n","\n","Accuracy of the network on the 2991 test images: 95.95 %\n","Accuracy of 궤양병 : 83.33 %\n","Accuracy of 잎곰팡이병 : 83.56 %\n","Accuracy of 점무늬병 : 95.87 %\n","Accuracy of 황화잎말림바이러스 : 81.82 %\n","Accuracy of 아메리카잎굴파리 : 94.50 %\n","Accuracy of 청벌레 : 43.75 %\n","Accuracy of 정상 : 99.87 %\n","\n","predicted tensor([4], device='cuda:0')\n","time 0.010610103607177734\n","\n","--------------Aug3 ResNet--------------\n","Confusion Matrix\n","[[  22    1   10    6    1    0    2]\n"," [   1  134    1    0    4    0    6]\n"," [   0    8  364    1    5    0    9]\n"," [   0    0    9   51    0    0   17]\n"," [   1    4    6    0  706    0   10]\n"," [   0    1    4    0    5    9   13]\n"," [   0    5    9    3    6    0 1557]]\n","\n","accuracy  : 0.950518\n","precision : 0.923939\n","recall    : 0.754619\n","f1-score  : 0.801247\n","\n","Accuracy of the network on the 2991 test images: 95.05 %\n","Accuracy of 궤양병 : 52.38 %\n","Accuracy of 잎곰팡이병 : 91.78 %\n","Accuracy of 점무늬병 : 94.06 %\n","Accuracy of 황화잎말림바이러스 : 66.23 %\n","Accuracy of 아메리카잎굴파리 : 97.11 %\n","Accuracy of 청벌레 : 28.12 %\n","Accuracy of 정상 : 98.54 %\n","\n","predicted tensor([4], device='cuda:0')\n","time 0.010223865509033203\n"],"name":"stdout"}]}]}